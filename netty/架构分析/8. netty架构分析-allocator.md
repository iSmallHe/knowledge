# Allocator

在分析Allocator之前，我们首先需要了解netty的处理机制：在读取数据时，由于

## 一、RecvByteBufAllocator

`RecvByteBufAllocator` 是 Netty 中负责接收字节缓冲区的组件。它主要在 `Channel` 的数据接收过程中，管理如何分配和调整字节缓冲区的大小。`RecvByteBufAllocator` 的目的是确保数据接收时能够高效地管理内存，避免过多或过少的内存分配。

在 Netty 中，接收数据的过程涉及到数据从网络层传输到应用层。为了处理这个过程，Netty 使用了 `RecvByteBufAllocator` 作为一种灵活的内存管理方案，来决定为每次接收操作分配多大的缓冲区。

### **1.1 主要接口**

`RecvByteBufAllocator` 是一个接口，它定义了接收缓冲区分配的主要方法。其实现类的主要职责是根据网络条件和接收的数据量动态调整分配的缓冲区大小。下面是接口的核心方法：

```java
public interface RecvByteBufAllocator {
    Handle newHandle();
    
    public interface Handle {
        // 调整缓冲区大小
        int guess();
        
        // 重置读取数据
        void reset(ChannelConfig config);
        
        // 增加当前循环读取的已读消息数量
        void incMessagesRead(int numMessages);

        // 设置上一次读取的字节数
        void lastBytesRead(int bytes);

        // 设置尝试读取的字节数
        void attemptedBytesRead(int bytes);

        // 是否继续读取
        boolean continueReading();

        // 读取完成
        void readComplete();
    }
}
```

### **1.2 关键方法**

#### **1. `newHandle()`**

这个方法返回一个 `Handle` 对象，该对象会用来获取和控制缓冲区的分配过程。`Handle` 维护了与当前通道的接收状态相关的信息，可以通过它动态调整分配缓冲区的策略。

#### **2. `Handle.guess()`**

`guess()` 方法根据当前的接收条件返回一个建议的缓冲区大小。这一大小由实现类根据通道接收到的数据量、网络负载等因素来动态计算。

#### **3. `Handle.reset(ChannelConfig config)`**

`reset()` 方法重置之前的计数器，或其他参数

#### **4. `Handle.incMessagesRead(int numMessages)`**

`incMessagesRead()` 方法用于统计接收到的消息数量。这有助于决定接下来的数据接收策略。例如，接收的数据量较大时，可能会动态调整缓冲区的分配策略。

#### **5. `Handle.continueReading()`**

`continueReading()` 方法用于判断是否继续读取。它是判断是否已经接收到足够数据的一种方式。在某些情况下，接收的数据量可能较小，此时可以选择停止读取，等待更多数据到来。

### **1.3 常见实现**

`RecvByteBufAllocator` 有几个常见的实现，这些实现根据不同的场景提供了不同的分配策略。

#### **1. DefaultMaxBytesRecvByteBufAllocator**

`DefaultMaxBytesRecvByteBufAllocator`以bytesToRead减去每次读取的字节数后，再预测后续缓冲区大小

```java
public class DefaultMaxBytesRecvByteBufAllocator implements MaxBytesRecvByteBufAllocator {
    private volatile int maxBytesPerRead;
    private volatile int maxBytesPerIndividualRead;

    private final class HandleImpl implements Handle {
        private int individualReadMax;
        private int bytesToRead;
        private int lastBytesRead;
        private int attemptBytesRead;
        @Override
        public ByteBuf allocate(ByteBufAllocator alloc) {
            return alloc.ioBuffer(guess());
        }
        @Override
        public int guess() {
            return Math.min(individualReadMax, bytesToRead);
        }
        @Override
        public void reset(ChannelConfig config) {
            bytesToRead = maxBytesPerRead();
            individualReadMax = maxBytesPerIndividualRead();
        }
        @Override
        public void incMessagesRead(int amt) {
        }
        @Override
        public void lastBytesRead(int bytes) {
            lastBytesRead = bytes;
            // Ignore if bytes is negative, the interface contract states it will be detected externally after call.
            // The value may be "invalid" after this point, but it doesn't matter because reading will be stopped.
            bytesToRead -= bytes;
        }
        @Override
        public int lastBytesRead() {
            return lastBytesRead;
        }
        @Override
        public boolean continueReading() {
            // Keep reading if we are allowed to read more bytes, and our last read filled up the buffer we provided.
            return bytesToRead > 0 && attemptBytesRead == lastBytesRead;
        }
        @Override
        public void readComplete() {
        }
        @Override
        public void attemptedBytesRead(int bytes) {
            attemptBytesRead = bytes;
        }
        @Override
        public int attemptedBytesRead() {
            return attemptBytesRead;
        }
    }
}
```

#### **2. AdaptiveRecvByteBufAllocator**

`AdaptiveRecvByteBufAllocator` 是最常用的实现，它根据历史接收的字节量来调整接收缓冲区的大小。它是一个 **自适应分配器**，根据过去接收到的数据量来做出分配决策。这种方式避免了每次都分配过多或过少的内存。

1. `SIZE_TABLE` 在512字节前，间隔是16字节，而在512值后，大小翻倍
2. 每次读取完成后`record`方法会根据读取的字节数来判断当前读取是否合理，不合理时会进行扩容/缩容

```java
public class AdaptiveRecvByteBufAllocator extends DefaultMaxMessagesRecvByteBufAllocator {

    static final int DEFAULT_MINIMUM = 64;
    static final int DEFAULT_INITIAL = 1024;
    static final int DEFAULT_MAXIMUM = 65536;

    private static final int INDEX_INCREMENT = 4;
    private static final int INDEX_DECREMENT = 1;

    private static final int[] SIZE_TABLE;

    static {
        List<Integer> sizeTable = new ArrayList<Integer>();
        for (int i = 16; i < 512; i += 16) {
            sizeTable.add(i);
        }

        for (int i = 512; i > 0; i <<= 1) {
            sizeTable.add(i);
        }

        SIZE_TABLE = new int[sizeTable.size()];
        for (int i = 0; i < SIZE_TABLE.length; i ++) {
            SIZE_TABLE[i] = sizeTable.get(i);
        }
    }

    /**
     * @deprecated There is state for {@link #maxMessagesPerRead()} which is typically based upon channel type.
     */
    @Deprecated
    public static final AdaptiveRecvByteBufAllocator DEFAULT = new AdaptiveRecvByteBufAllocator();

    private static int getSizeTableIndex(final int size) {
        for (int low = 0, high = SIZE_TABLE.length - 1;;) {
            if (high < low) {
                return low;
            }
            if (high == low) {
                return high;
            }

            int mid = low + high >>> 1;
            int a = SIZE_TABLE[mid];
            int b = SIZE_TABLE[mid + 1];
            if (size > b) {
                low = mid + 1;
            } else if (size < a) {
                high = mid - 1;
            } else if (size == a) {
                return mid;
            } else {
                return mid + 1;
            }
        }
    }

    private final class HandleImpl extends MaxMessageHandle {
        private final int minIndex;
        private final int maxIndex;
        private int index;
        private int nextReceiveBufferSize;
        private boolean decreaseNow;

        public HandleImpl(int minIndex, int maxIndex, int initial) {
            this.minIndex = minIndex;
            this.maxIndex = maxIndex;

            index = getSizeTableIndex(initial);
            nextReceiveBufferSize = SIZE_TABLE[index];
        }

        @Override
        public int guess() {
            return nextReceiveBufferSize;
        }

        private void record(int actualReadBytes) {
            if (actualReadBytes <= SIZE_TABLE[Math.max(0, index - INDEX_DECREMENT - 1)]) {
                if (decreaseNow) {
                    index = Math.max(index - INDEX_DECREMENT, minIndex);
                    nextReceiveBufferSize = SIZE_TABLE[index];
                    decreaseNow = false;
                } else {
                    decreaseNow = true;
                }
            } else if (actualReadBytes >= nextReceiveBufferSize) {
                index = Math.min(index + INDEX_INCREMENT, maxIndex);
                nextReceiveBufferSize = SIZE_TABLE[index];
                decreaseNow = false;
            }
        }

        @Override
        public void readComplete() {
            record(totalBytesRead());
        }
    }

    private final int minIndex;
    private final int maxIndex;
    private final int initial;

    /**
     * Creates a new predictor with the default parameters.  With the default
     * parameters, the expected buffer size starts from {@code 1024}, does not
     * go down below {@code 64}, and does not go up above {@code 65536}.
     */
    public AdaptiveRecvByteBufAllocator() {
        this(DEFAULT_MINIMUM, DEFAULT_INITIAL, DEFAULT_MAXIMUM);
    }

    /**
     * Creates a new predictor with the specified parameters.
     *
     * @param minimum  the inclusive lower bound of the expected buffer size
     * @param initial  the initial buffer size when no feed back was received
     * @param maximum  the inclusive upper bound of the expected buffer size
     */
    public AdaptiveRecvByteBufAllocator(int minimum, int initial, int maximum) {
        if (minimum <= 0) {
            throw new IllegalArgumentException("minimum: " + minimum);
        }
        if (initial < minimum) {
            throw new IllegalArgumentException("initial: " + initial);
        }
        if (maximum < initial) {
            throw new IllegalArgumentException("maximum: " + maximum);
        }

        int minIndex = getSizeTableIndex(minimum);
        if (SIZE_TABLE[minIndex] < minimum) {
            this.minIndex = minIndex + 1;
        } else {
            this.minIndex = minIndex;
        }

        int maxIndex = getSizeTableIndex(maximum);
        if (SIZE_TABLE[maxIndex] > maximum) {
            this.maxIndex = maxIndex - 1;
        } else {
            this.maxIndex = maxIndex;
        }

        this.initial = initial;
    }

    @Override
    public Handle newHandle() {
        return new HandleImpl(minIndex, maxIndex, initial);
    }
}
```

#### **3. FixedRecvByteBufAllocator**

`FixedRecvByteBufAllocator` 是另一种实现，它为每次接收操作分配固定大小的缓冲区。这对于固定大小的数据传输非常有用，但可能会浪费内存，特别是在数据大小变化较大的情况下。

```java
public class FixedRecvByteBufAllocator implements RecvByteBufAllocator {
    private final int bufferSize;

    public FixedRecvByteBufAllocator(int bufferSize) {
        this.bufferSize = bufferSize;
    }

    @Override
    public Handle newHandle() {
        return new FixedHandle(bufferSize);
    }

    static final class FixedHandle implements RecvByteBufAllocator.Handle {
        private final int bufferSize;

        FixedHandle(int bufferSize) {
            this.bufferSize = bufferSize;
        }

        @Override
        public int guess() {
            return bufferSize;
        }

        @Override
        public void reset(int capacity) {
            // Do nothing, fixed size
        }

        @Override
        public void incMessagesRead(int numMessages) {
            // No-op, fixed size
        }

        @Override
        public boolean continueReading() {
            return true; // Always continue reading
        }
    }
}
```

在这种实现中，接收缓冲区的大小始终是固定的，适合一些内存使用可预测的场景。

### **总结**

`RecvByteBufAllocator` 是 Netty 用于优化内存分配、管理接收缓冲区的核心组件。不同的实现可以根据不同的场景来优化内存使用和数据接收的效率，常见的实现包括自适应的 `AdaptiveRecvByteBufAllocator` 和固定大小的 `FixedRecvByteBufAllocator`。它通过缓冲区的动态分配和调整，优化了内存的使用，避免了内存过度分配和不足的问题。

## 二、ByteBufAllocator


下面提供一个关于 Netty 中 **ByteBufAllocator** 源码的详细分析，帮助理解它的设计思想、接口定义以及主要实现（如 PooledByteBufAllocator 与 UnpooledByteBufAllocator）的工作原理。

---

### 2.1 概述

**ByteBufAllocator** 是 Netty 提供的一个接口，其主要作用是负责分配和回收 **ByteBuf** 对象。由于网络应用对内存分配与释放的要求非常严格，为了获得更高的性能和更低的 GC 压力，Netty 设计了灵活的 ByteBuf 分配机制。  
在实际使用中，Netty 提供了两种主要的 ByteBufAllocator 实现：

- **PooledByteBufAllocator**  
  使用内存池（pool）来管理内存，复用内存块以降低频繁申请和释放带来的开销，适用于对性能要求较高的场景（默认使用）。

- **UnpooledByteBufAllocator**  
  不使用内存池，每次分配都直接申请新的内存，适用于对内存复用要求不高或者调试场景。

---

### 2.2 ByteBufAllocator 接口

#### 2.2.1 接口定义

Netty 中 **ByteBufAllocator** 接口定义了一系列用于分配 ByteBuf 的方法。常见方法如下（部分方法）：

```java
public interface ByteBufAllocator {
    // 分配堆缓冲区
    ByteBuf buffer();
    ByteBuf buffer(int initialCapacity);
    ByteBuf buffer(int initialCapacity, int maxCapacity);

    // 分配直接内存缓冲区
    ByteBuf directBuffer();
    ByteBuf directBuffer(int initialCapacity);
    ByteBuf directBuffer(int initialCapacity, int maxCapacity);

    // 分配 I/O 缓冲区（通常会选择直接内存或者堆内存，取决于系统实现）
    ByteBuf ioBuffer();
    ByteBuf ioBuffer(int initialCapacity);
    ByteBuf ioBuffer(int initialCapacity, int maxCapacity);

    // 分配组合缓冲区（CompositeByteBuf）
    CompositeByteBuf compositeBuffer();
    CompositeByteBuf compositeBuffer(int maxNumComponents);
    // ... 其他辅助方法
}
```

这些方法为用户提供了灵活的内存分配方式，可以根据具体需求申请不同类型、不同容量的缓冲区。

#### 2.2.2 设计意图

- **统一接口：** 通过统一的接口定义，用户无需关心具体内存分配的实现细节（如是否使用内存池）。
- **灵活性：** 可以选择分配堆内存（heap buffer）或直接内存（direct buffer），以及是否使用组合缓冲区（CompositeByteBuf）。
- **性能优化：** 内存池实现（PooledByteBufAllocator）通过预先分配内存块并复用它们，减少了频繁申请和释放内存所带来的开销，同时降低了垃圾回收（GC）的压力。

---

### 2.3 主要实现：PooledByteBufAllocator

#### 2.3.1 主要目标

**PooledByteBufAllocator** 的核心目标是通过内存池技术来降低内存分配的成本。其设计中包含了以下几个关键要素：

- **内存划分与分级：**  
  内存被划分为多个“arena”，每个 arena 又管理多个大块内存（chunk）。这些 chunk 内部会按照不同大小的区间进一步管理（通过 PoolSubpage 机制），从而支持小对象的复用。

- **线程本地缓存：**  
  为了减少跨线程竞争，PooledByteBufAllocator 为每个线程提供了线程局部缓存（ThreadLocalCache），使得大部分内存申请可以在本线程内完成。

- **分配策略与回收机制：**  
  分配时会根据申请的大小选择合适的内存池（heapArena 或 directArena），并通过“池化”算法分配内存；释放时，则将内存返回到对应的池中，以便后续复用。

#### 2.3.2 内部类结构

主要涉及的内部类有：
- **PoolArena**  
  管理一片内存池，包括若干个 PoolChunk（大块内存）和 PoolSubpage（用于小对象分配的细分页面）。
  
- **PoolChunk**  
  表示一大块连续的内存空间，在分配时进一步切分成若干块。
  
- **PoolSubpage**  
  用于管理小于 PageSize 的内存分配，通过链表结构管理可用的小块内存。

- **PoolThreadCache**  
  线程局部缓存，缓存了从 PoolArena 中分配出的内存块，减少了跨线程的竞争。

#### 2.3.3 分配过程示例

当调用 `PooledByteBufAllocator.buffer()` 时，内部大致流程如下：
1. **确定请求大小：**  
   根据用户请求确定初始容量和最大容量。
2. **选择 arena：**  
   根据当前线程信息，从线程局部缓存中查找对应的 arena（heapArena 或 directArena）。
3. **尝试从线程缓存中分配：**  
   如果线程缓存中有合适的内存块，则直接返回，否则进入下一步。
4. **从 arena 分配：**  
   调用对应的 PoolArena 的分配方法，从内部管理的 PoolChunk 或 PoolSubpage 中分配内存块。
5. **封装为 ByteBuf：**  
   分配到内存后，将内存块封装成 ByteBuf 对象，并设置好读写索引、容量等信息返回给调用方。

这种设计使得内存分配的性能大大提升，并且可以在大量短命连接、频繁数据传输的场景下保持良好的性能表现。

---

### 2.4 另一实现：UnpooledByteBufAllocator

**UnpooledByteBufAllocator** 实现较为简单，它每次分配内存时都直接调用 JDK 的内存分配（例如通过 `ByteBuffer.allocate()` 或 `ByteBuffer.allocateDirect()`）：
- **无池化：** 每次分配都新建对象，不做内存复用。
- **适用场景：** 在一些对内存分配性能要求不高、或者调试与测试时可能更方便的场景下使用。

由于缺乏内存池复用机制，UnpooledByteBufAllocator 的内存分配和回收开销会相对较大，因此在生产环境中通常使用 PooledByteBufAllocator。

---

### 2.5 源码分析总结

- **接口定义层面：**  
  ByteBufAllocator 提供了一套统一的 API，使得上层应用代码可以独立于具体的内存分配实现。

- **实现层面：**  
  - **PooledByteBufAllocator** 通过内存池（arena、chunk、subpage）和线程局部缓存来优化内存分配，减少 GC 压力，提高性能。  
  - **UnpooledByteBufAllocator** 则直接分配新的内存，简单直接但性能较低。

- **设计优势：**  
  这种设计使得 Netty 能够在高性能网络应用中高效地管理内存，避免因频繁申请和释放内存而导致的性能瓶颈，同时也提供了灵活的配置选项，允许用户根据不同需求选择合适的内存分配器。

---

以上就是对 Netty 中 **ByteBufAllocator** 的源码分析与工作原理的详细讲解。如果你对某个具体实现（例如 PooledByteBufAllocator 内部某个方法或类）的细节有更多疑问，可以进一步查看 Netty 的源码并结合调试信息进行深入理解。
